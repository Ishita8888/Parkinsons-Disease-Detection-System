{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6903f12a-e52b-4989-a3e6-16a4ccad23f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaisw\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of training data: 0.9807692170143127\n",
      "Accuracy of testing data: 0.7948718070983887\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "Positive, Parkinson's Found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaisw\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"parkinsons.csv\")\n",
    "\n",
    "# Prepare data\n",
    "X = df.drop(columns=['name', 'status'], axis=1)\n",
    "Y = df['status']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)\n",
    "\n",
    "# Data scaling\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train)\n",
    "X_train = ss.transform(X_train)\n",
    "X_test = ss.transform(X_test)\n",
    "\n",
    "# Define the ANN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, Y_train, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "# Evaluate the model\n",
    "train_data_acc = model.evaluate(X_train, Y_train, verbose=0)[1]\n",
    "test_data_acc = model.evaluate(X_test, Y_test, verbose=0)[1]\n",
    "\n",
    "print(\"Accuracy of training data:\", train_data_acc)\n",
    "print(\"Accuracy of testing data:\", test_data_acc)\n",
    "\n",
    "# Example prediction\n",
    "input_data = np.array([[115.68200, 131.11100, 111.55500, 0.01050, 0.00009, 0.00544, 0.00781, 0.01633, 0.05233, 0.48200, 0.02757, 0.03858, 0.03590, 0.08270, 0.01309, 20.65100, 0.429895, 0.825288, -4.443179, 0.311173, 2.342259, 0.332634]])\n",
    "input_data_re = ss.transform(input_data)\n",
    "pred = model.predict(input_data_re)\n",
    "\n",
    "if pred[0][0] < 0.5:\n",
    "    print(\"Negative, No Parkinson's Found\")\n",
    "else:\n",
    "    print(\"Positive, Parkinson's Found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7591b6f5-7235-45a9-b0b3-978da54333ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaisw\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Neural Network (ANN) - Train Accuracy: 0.9807692170143127 , Test Accuracy: 0.7435897588729858\n",
      "k-Nearest Neighbors (KNN) - Train Accuracy: 0.967948717948718 , Test Accuracy: 0.7692307692307693\n",
      "XGBoost - Train Accuracy: 1.0 , Test Accuracy: 0.8717948717948718\n",
      "Gradient Boosting - Train Accuracy: 1.0 , Test Accuracy: 0.8205128205128205\n",
      "Best Model Selected with Test Accuracy: 0.8717948717948718\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"parkinsons.csv\")\n",
    "\n",
    "# Prepare data\n",
    "X = df.drop(columns=['name', 'status'], axis=1)\n",
    "Y = df['status']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)\n",
    "\n",
    "# Data scaling for algorithms that require it\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Artificial Neural Network (ANN)\n",
    "model_ann = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model_ann.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_ann.fit(X_train_scaled, Y_train, epochs=50, batch_size=32, verbose=0)\n",
    "ann_train_acc = model_ann.evaluate(X_train_scaled, Y_train, verbose=0)[1]\n",
    "ann_test_acc = model_ann.evaluate(X_test_scaled, Y_test, verbose=0)[1]\n",
    "\n",
    "# k-Nearest Neighbors (KNN)\n",
    "model_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "model_knn.fit(X_train_scaled, Y_train)\n",
    "knn_train_acc = model_knn.score(X_train_scaled, Y_train)\n",
    "knn_test_acc = model_knn.score(X_test_scaled, Y_test)\n",
    "\n",
    "# XGBoost\n",
    "model_xgb = xgb.XGBClassifier()\n",
    "model_xgb.fit(X_train_scaled, Y_train)\n",
    "xgb_train_acc = accuracy_score(Y_train, model_xgb.predict(X_train_scaled))\n",
    "xgb_test_acc = accuracy_score(Y_test, model_xgb.predict(X_test_scaled))\n",
    "\n",
    "# Gradient Boosting\n",
    "model_gb = GradientBoostingClassifier()\n",
    "model_gb.fit(X_train_scaled, Y_train)\n",
    "gb_train_acc = accuracy_score(Y_train, model_gb.predict(X_train_scaled))\n",
    "gb_test_acc = accuracy_score(Y_test, model_gb.predict(X_test_scaled))\n",
    "\n",
    "# Printing accuracy of all algorithms\n",
    "print(\"Artificial Neural Network (ANN) - Train Accuracy:\", ann_train_acc, \", Test Accuracy:\", ann_test_acc)\n",
    "print(\"k-Nearest Neighbors (KNN) - Train Accuracy:\", knn_train_acc, \", Test Accuracy:\", knn_test_acc)\n",
    "print(\"XGBoost - Train Accuracy:\", xgb_train_acc, \", Test Accuracy:\", xgb_test_acc)\n",
    "print(\"Gradient Boosting - Train Accuracy:\", gb_train_acc, \", Test Accuracy:\", gb_test_acc)\n",
    "\n",
    "# Selecting the best model\n",
    "best_model = None\n",
    "best_accuracy = 0\n",
    "\n",
    "if ann_test_acc > best_accuracy:\n",
    "    best_model = model_ann\n",
    "    best_accuracy = ann_test_acc\n",
    "\n",
    "if knn_test_acc > best_accuracy:\n",
    "    best_model = model_knn\n",
    "    best_accuracy = knn_test_acc\n",
    "\n",
    "if xgb_test_acc > best_accuracy:\n",
    "    best_model = model_xgb\n",
    "    best_accuracy = xgb_test_acc\n",
    "\n",
    "if gb_test_acc > best_accuracy:\n",
    "    best_model = model_gb\n",
    "    best_accuracy = gb_test_acc\n",
    "\n",
    "print(\"Best Model Selected with Test Accuracy:\", best_accuracy)\n",
    "\n",
    "# Now you can use the best_model for making predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6b07970-4833-484b-a200-28dd4bd5e16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive, Parkinson's Found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaisw\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Now you can use the best_model for making predictions.\n",
    "\n",
    "# Assuming `input_data` contains the new data for prediction\n",
    "input_data = np.array([[115.68200, 131.11100, 111.55500, 0.01050, 0.00009, 0.00544, 0.00781, 0.01633, 0.05233, 0.48200, 0.02757, 0.03858, 0.03590, 0.08270, 0.01309, 20.65100, 0.429895, 0.825288, -4.443179, 0.311173, 2.342259, 0.332634]])\n",
    "input_data_scaled = scaler.transform(input_data)  # Scale the input data\n",
    "\n",
    "# Making predictions using the best model (XGBoost)\n",
    "predictions = best_model.predict(input_data_scaled)\n",
    "\n",
    "# Output the predictions\n",
    "if predictions[0] == 0:\n",
    "    print(\"Negative, No Parkinson's Found\")\n",
    "else:\n",
    "    print(\"Positive, Parkinson's Found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a17baec-5e0d-4b36-9857-cb84315147b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
